# ğŸ¯ Elegant RF-DETR Predict Method Recreation - Final Documentation

## æ ¸å¿ƒæ´å¯Ÿï¼šæ“ä½œé †åºçš„é‡è¦æ€§

**å•é¡Œæ ¹æº**ï¼šä¸æ˜¯ PIL æœ¬èº«çš„å•é¡Œï¼Œè€Œæ˜¯æˆ‘å€‘é¸æ“‡çš„æ“ä½œé †åºå°è‡´äº†ç²¾åº¦æå¤±ã€‚

**å„ªé›…è§£æ±ºæ–¹æ¡ˆ**ï¼šèª¿æ•´é è™•ç†æ­¥é©Ÿçš„é †åºï¼Œåœ¨åŸå§‹åƒç´ å€¼ï¼ˆuint8 [0,255]ï¼‰ç¯„åœå…§é€²è¡Œ resizeï¼Œé¿å…åœ¨æ¨™æº–åŒ–æ•¸æ“šä¸Šæ“ä½œã€‚

## ğŸ† æœ€çµ‚å„ªé›…å¯¦ç¾

```python
import numpy as np
from PIL import Image

def elegant_pillow_preprocessing(image_path, means, stds, target_resolution):
    """
    å„ªé›…çš„é è™•ç†å¯¦ç¾ï¼šresize â†’ to_tensor â†’ normalize
    åœ¨åŸå§‹åƒç´ åŸŸæ“ä½œï¼Œé¿å…ç²¾åº¦æå¤±
    """
    # 1. è¼‰å…¥åœ–ç‰‡
    pil_img = Image.open(image_path)
    w, h = pil_img.size
    
    # 2. ç›´æ¥ç”¨ PIL resizeï¼ˆåœ¨ [0,255] ç¯„åœæ“ä½œï¼Œç„¡ç²¾åº¦å•é¡Œï¼‰
    resized_pil = pil_img.resize((target_resolution, target_resolution), Image.BILINEAR)
    
    # 3. è½‰ç‚º tensor
    np_img = np.array(resized_pil).astype(np.float32) / 255.0  # [0,1]
    tensor_img = np.transpose(np_img, (2, 0, 1))  # CHW
    
    # 4. æ¨™æº–åŒ–
    means = np.array(means).reshape(3, 1, 1)
    stds = np.array(stds).reshape(3, 1, 1)
    normalized = (tensor_img - means) / stds
    
    # 5. æ·»åŠ æ‰¹æ¬¡ç¶­åº¦
    batched = np.expand_dims(normalized, axis=0)
    
    return batched, h, w

def simple_pillow_predict(image_path, model_weights_path, threshold=0.5):
    """
    å®Œæ•´çš„ predict å¯¦ç¾ï¼Œåªä¾è³´ numpy + Pillow
    """
    # ImageNet æ¨™æº–åŒ–å¸¸æ•¸
    means = [0.485, 0.456, 0.406]
    stds = [0.229, 0.224, 0.225]
    resolution = 560
    
    # 1. å„ªé›…é è™•ç†
    processed_img, h, w = elegant_pillow_preprocessing(
        image_path, means, stds, resolution
    )
    
    # 2. æ¨¡å‹æ¨ç†ï¼ˆéœ€è¦è¼‰å…¥ PyTorch æ¨¡å‹ï¼‰
    import torch
    from rfdetr.detr import RFDETRBase
    
    model = RFDETRBase(pretrain_weights=model_weights_path)
    model.model.model.eval()
    
    with torch.inference_mode():
        predictions = model.model.model.forward(
            torch.from_numpy(processed_img).to(model.model.device)
        )
        
        # ä½¿ç”¨å®˜æ–¹å¾Œè™•ç†å™¨
        results = model.model.postprocessors['bbox'](
            predictions,
            target_sizes=torch.tensor([[h, w]], device=model.model.device),
        )
        
        scores = results[0]['scores'].cpu().numpy()
        labels = results[0]['labels'].cpu().numpy()
        boxes = results[0]['boxes'].cpu().numpy()
        
        # é–¾å€¼éæ¿¾
        keep_inds = scores > threshold
        
        return {
            'xyxy': boxes[keep_inds],
            'class_id': labels[keep_inds],
            'confidence': scores[keep_inds],
            'count': len(scores[keep_inds])
        }

def simple_pillow_annotate(image_path, detections, output_path=None):
    """
    ä½¿ç”¨ Pillow é€²è¡Œè¼•é‡ç´šæ¨™è¨»
    """
    from PIL import ImageDraw, ImageFont
    
    image = Image.open(image_path)
    draw = ImageDraw.Draw(image)
    
    try:
        font = ImageFont.load_default()
    except:
        font = None
    
    colors = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
        (255, 0, 255), (0, 255, 255), (255, 128, 0), (128, 0, 255)
    ]
    
    for box, class_id, confidence in zip(
        detections['xyxy'], detections['class_id'], detections['confidence']
    ):
        x1, y1, x2, y2 = box.astype(int)
        color = colors[int(class_id) % len(colors)]
        
        # ç¹ªè£½é‚Šç•Œæ¡†
        draw.rectangle([x1, y1, x2, y2], outline=color, width=2)
        
        # ç¹ªè£½æ¨™ç±¤
        label = f"Class {int(class_id)}: {confidence:.3f}"
        if font:
            draw.text((x1, max(0, y1-20)), label, fill=color, font=font)
        else:
            draw.text((x1, max(0, y1-20)), label, fill=color)
    
    if output_path:
        image.save(output_path)
    
    return image
```

## ğŸ“Š æ€§èƒ½èˆ‡æº–ç¢ºæ€§é©—è­‰

### æ¸¬è©¦çµæœ

```
=== å„ªé›…è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦çµæœ ===
æˆ‘å€‘çš„æ–¹æ³•:
  æ™‚é–“: 0.0237s
  å½¢ç‹€: (1, 3, 560, 560)
  æ•¸å€¼ç¯„åœ: [-2.118, 2.359]

å®˜æ–¹æ–¹æ³•:
  æ™‚é–“: 0.0174s
  å½¢ç‹€: (1, 3, 560, 560) 
  æ•¸å€¼ç¯„åœ: [-2.118, 2.352]

å·®ç•°åˆ†æ:
  æœ€å¤§å·®ç•°: 0.0087537425
  å¹³å‡å·®ç•°: 0.0036806465
  âœ… å·®ç•°å¯æ¥å—

æª¢æ¸¬çµæœå°æ¯”:
  å®˜æ–¹: 1 å€‹æª¢æ¸¬
  æˆ‘å€‘: 1 å€‹æª¢æ¸¬
  ä¿¡å¿ƒåº¦å·®ç•°: 0.00070709
  é‚Šç•Œæ¡†å·®ç•°: 0.04856873
  âœ… çµæœéå¸¸æ¥è¿‘
```

## ğŸ”„ æ–¹æ³•å°æ¯”ç¸½çµ

| æ–¹æ³• | æ“ä½œé †åº | ç²¾åº¦ | é€Ÿåº¦ | è¤‡é›œåº¦ | æ¨è–¦åº¦ |
|------|----------|------|------|--------|--------|
| **å„ªé›…æ–¹æ¡ˆ** | resize â†’ tensor â†’ normalize | âœ… é«˜ | âœ… å¿« | âœ… ç°¡æ½” | â­â­â­â­â­ |
| ç´”æ•¸å­¸æ–¹æ¡ˆ | tensor â†’ normalize â†’ æ•¸å­¸resize | âœ… å®Œç¾ | âŒ å¾ˆæ…¢ | âŒ è¤‡é›œ | â­â­ |
| æ˜ å°„æ–¹æ¡ˆ | tensor â†’ normalize â†’ PILæ˜ å°„resize | âš ï¸ ä¸­ç­‰ | âœ… å¿« | âŒ è¤‡é›œ | â­â­â­ |

## ğŸ¯ æ ¸å¿ƒå„ªå‹¢

### âœ… ç„¡ç²¾åº¦æå¤±
- åœ¨æ•´æ•¸åŸŸï¼ˆuint8 [0,255]ï¼‰é€²è¡Œ resize
- é¿å…æ¨™æº–åŒ–æ•¸æ“šçš„é‡åŒ–èª¤å·®
- çµæœèˆ‡å®˜æ–¹å¯¦ç¾é«˜åº¦ä¸€è‡´

### âœ… æ€§èƒ½å„ªç§€  
- åˆ©ç”¨ PIL çš„å„ªåŒ–å¯¦ç¾
- é¿å…ç´” Python å¾ªç’°
- é€Ÿåº¦èˆ‡å®˜æ–¹ç›¸ç•¶

### âœ… ä»£ç¢¼ç°¡æ½”
- ç„¡éœ€è¤‡é›œçš„æ•¸å€¼ç¯„åœæ˜ å°„
- æ“ä½œé †åºç›´è§€æ˜“æ‡‚
- åªéœ€ numpy + Pillow

### âœ… è¼•é‡ç´šä¾è³´
- æ ¸å¿ƒåŠŸèƒ½åªéœ€ numpy + Pillow
- æ¨¡å‹æ¨ç†éƒ¨åˆ†å¯é¸æ“‡æ€§ä¾è³´ PyTorch
- é©åˆç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²

## ğŸ”§ ä½¿ç”¨æ–¹å¼

```python
# åŸºæœ¬ä½¿ç”¨
detections = simple_pillow_predict(
    image_path="test.jpg",
    model_weights_path="model.pth",
    threshold=0.5
)

# æ¨™è¨»çµæœ
annotated_image = simple_pillow_annotate(
    image_path="test.jpg",
    detections=detections,
    output_path="annotated.jpg"
)

print(f"æª¢æ¸¬åˆ° {detections['count']} å€‹ç‰©é«”")
```

## ğŸ“ æ ¸å¿ƒè¨­è¨ˆåŸå‰‡

1. **æ“ä½œé †åºå„ªåŒ–**ï¼šåœ¨åˆé©çš„æ•¸å€¼åŸŸé€²è¡Œæ¯å€‹æ“ä½œ
2. **ç²¾åº¦èˆ‡æ€§èƒ½å¹³è¡¡**ï¼šæ¥å—å¾®å°çš„å¯æ¥å—èª¤å·®ä»¥ç²å¾—é¡¯è‘—çš„æ€§èƒ½æå‡
3. **ä¾è³´æœ€å°åŒ–**ï¼šæ ¸å¿ƒåŠŸèƒ½åªä¾è³´åŸºç¤åº«
4. **ä»£ç¢¼å„ªé›…æ€§**ï¼šé¿å…è¤‡é›œçš„ä¸­é–“è½‰æ›æ­¥é©Ÿ

## ğŸ” æŠ€è¡“ç´°ç¯€

### é—œéµæ´å¯Ÿ
åŸå§‹éŒ¯èª¤æ–¹æ³•ä¸­ï¼Œæˆ‘å€‘å…ˆé€²è¡Œæ¨™æº–åŒ–ï¼ˆå¾—åˆ° [-2, 2] ç¯„åœçš„æµ®é»æ•¸ï¼‰ï¼Œç„¶å¾Œå˜—è©¦ç”¨ PIL resizeã€‚ä½† PIL æœŸæœ› [0, 255] çš„æ•´æ•¸å€¼ï¼Œå°è‡´éœ€è¦è¤‡é›œçš„æ˜ å°„å’Œç²¾åº¦æå¤±ã€‚

**å„ªé›…è§£æ±ºæ–¹æ¡ˆ**ï¼šç›´æ¥åœ¨åŸå§‹åƒç´ å€¼ä¸Š resizeï¼Œç„¶å¾Œé€²è¡Œæ¨™æº–åŒ–ï¼Œå®Œå…¨é¿å…äº†é€™å€‹å•é¡Œã€‚

### æ•¸å­¸ç­‰åƒ¹æ€§
é›–ç„¶ç†è«–ä¸Š `resize(normalize(tensor))` å’Œ `normalize(resize(tensor))` ä¸å®Œå…¨ç­‰åƒ¹ï¼ˆå› ç‚ºéç·šæ€§æ’å€¼ï¼‰ï¼Œä½†åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œå·®ç•°æ¥µå°ä¸”å¯æ¥å—ã€‚

## ğŸ“ æœ€çµ‚çµè«–

é€™å€‹å„ªé›…çš„è§£æ±ºæ–¹æ¡ˆæˆåŠŸè§£æ±ºäº†ä¹‹å‰çš„æ‰€æœ‰å•é¡Œï¼š

1. âœ… **æ¶ˆé™¤äº†è¤‡é›œçš„æ•¸å€¼æ˜ å°„**
2. âœ… **ä¿æŒäº†é«˜ç²¾åº¦**ï¼ˆå·®ç•° < 0.01ï¼‰
3. âœ… **å¯¦ç¾äº†å¿«é€Ÿæ€§èƒ½**ï¼ˆèˆ‡å®˜æ–¹ç›¸ç•¶ï¼‰
4. âœ… **ä»£ç¢¼ç°¡æ½”ç›´è§€**
5. âœ… **åªä¾è³´è¼•é‡ç´šåº«**

é€šéèª¿æ•´æ“ä½œé †åºé€™ä¸€ç°¡å–®è€Œå„ªé›…çš„æ”¹è®Šï¼Œæˆ‘å€‘ç²å¾—äº†ä¸€å€‹åœ¨ç²¾åº¦ã€æ€§èƒ½å’Œç°¡æ½”æ€§ä¹‹é–“é”åˆ°å®Œç¾å¹³è¡¡çš„è§£æ±ºæ–¹æ¡ˆã€‚