"""
è—¥ä¸¸æª¢æ¸¬æ ¸å¿ƒæ¨¡çµ„ - RF-DETR ONNXæ¨ç†å¼•æ“

ä¸»è¦åŠŸèƒ½ï¼š
- é è™•ç†æµç¨‹ï¼šresize â†’ to_tensor â†’ normalizeï¼ˆåœ¨åŸå§‹åƒç´ åŸŸæ“ä½œï¼Œé¿å…ç²¾åº¦æå¤±ï¼‰
- RF-DETR ONNX æ¨¡å‹æ¨ç†
- ä¾è³´ numpy + Pillowï¼Œç§»é™¤PyTorchä¾è³´
- è·è²¬åˆ†é›¢ï¼šå°ˆæ³¨æª¢æ¸¬ï¼Œæ¨™è¨»ç”±detection_serviceè™•ç†

æŠ€è¡“è¦ç¯„åƒè€ƒï¼š
- docs/01_TECHNICAL_JOURNEY_COMPACT.mdï¼ˆæ¼”é€²ç¸½è¦½ï¼‰
- legacy/elegant_solution_spec.mdï¼ˆPillow å¯¦ç¾è©³ç´°èªªæ˜ï¼‰
- legacy/rfdetr_original_spec.mdï¼ˆåŸå§‹RF-DETRå¯¦ç¾è¦ç¯„ï¼‰
"""
import os
import json
import logging
from typing import List, Dict, Tuple
import numpy as np
import onnxruntime as ort
from PIL import Image

from .config import *
from .utils.coordinate_utils import CoordinateUtils

logger = logging.getLogger(__name__)

class PillDetector:
    """
    è—¥ä¸¸æª¢æ¸¬å™¨ - RF-DETR ONNXæ¨ç†æ ¸å¿ƒ
    
    å¯¦ç¾RF-DETR predictæ–¹æ³•çš„ONNXç‰ˆæœ¬ï¼š
    
    æ¶æ§‹è¨­è¨ˆï¼š
    - é è™•ç†ï¼šresize â†’ to_tensor â†’ normalize æµç¨‹
    - æ¨ç†ï¼šONNX Runtime æ¨ç†ï¼Œæ›¿ä»£PyTorch
    - å¾Œè™•ç†ï¼šæ¯ä½ç½®æœ€é«˜åˆ†é¡ â†’ é–¾å€¼éæ¿¾ â†’ Top-Ké¸æ“‡
    - åº§æ¨™è½‰æ›ï¼šcxcywh â†’ xyxyï¼Œä¸¦ç¸®æ”¾åˆ°è™•ç†å¾Œåœ–åƒå°ºå¯¸
    
    æŠ€è¡“ç‰¹é»ï¼š
    - åœ¨åŸå§‹åƒç´ åŸŸï¼ˆuint8 [0,255]ï¼‰é€²è¡Œresizeï¼Œé¿å…ç²¾åº¦æå¤±
    - æ”¯æ´é•·å¯¬æ¯”ä¿æŒçš„resize + paddingåˆ°560x560
    - åƒ…ä¾è³´ numpy + Pillow + ONNX Runtimeï¼Œç„¡OpenCV
    - è·è²¬å–®ä¸€ï¼šåƒ…è² è²¬æª¢æ¸¬ï¼Œæ¨™è¨»äº¤ç”±detection_service
    """
    
    def __init__(self):
        self.onnx_session = None
        self.class_names = None
        # ç§»é™¤ImageAnnotatorå¯¦ä¾‹ï¼Œç”±detection_serviceçµ±ä¸€ç®¡ç†
        
    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹å’Œé¡åˆ¥åç¨±"""
        await self._load_model()
        await self._load_class_names()
        
    async def _load_model(self):
        """è¼‰å…¥ ONNX æ¨¡å‹"""
        try:
            if not os.path.exists(MODEL_PATH):
                logger.error(f"ONNX æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {MODEL_PATH}")
                raise FileNotFoundError("ONNX æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
            
            # é…ç½® ONNX Runtime æ€§èƒ½å„ªåŒ–è¨­å®š
            sess_options = ort.SessionOptions()
            sess_options.inter_op_num_threads = INTER_OP_NUM_THREADS
            sess_options.intra_op_num_threads = INTRA_OP_NUM_THREADS
            sess_options.graph_optimization_level = getattr(ort.GraphOptimizationLevel, GRAPH_OPTIMIZATION_LEVEL)
            sess_options.execution_mode = getattr(ort.ExecutionMode, EXECUTION_MODE)
            sess_options.enable_mem_pattern = ENABLE_MEM_PATTERN
            sess_options.enable_cpu_mem_arena = ENABLE_CPU_MEM_ARENA
            
            # å¯é¸æ€§èƒ½åˆ†æï¼ˆèª¿è©¦ç”¨ï¼‰
            if ENABLE_PROFILING:
                sess_options.enable_profiling = True
                logger.info("ğŸ” ONNX æ€§èƒ½åˆ†æå·²å•Ÿç”¨")
                
            self.onnx_session = ort.InferenceSession(
                MODEL_PATH,
                sess_options=sess_options,
                providers=ONNX_PROVIDERS
            )
            logger.info("âœ… ONNX æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            logger.info(f"ğŸ” æ¨¡å‹è¼¸å…¥: {[inp.name for inp in self.onnx_session.get_inputs()]}")
            logger.info(f"ğŸ“¤ æ¨¡å‹è¼¸å‡º: {[out.name for out in self.onnx_session.get_outputs()]}")
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥ ONNX æ¨¡å‹å¤±æ•—: {str(e)}")
            raise Exception("æ¨¡å‹è¼‰å…¥å¤±æ•—")
            
    async def _load_class_names(self):
        """è¼‰å…¥é¡åˆ¥åç¨±"""
        try:
            if not os.path.exists(COCO_ANNOTATIONS_PATH):
                logger.error(f"COCO æ¨™è¨»æª”æ¡ˆä¸å­˜åœ¨: {COCO_ANNOTATIONS_PATH}")
                raise FileNotFoundError("é¡åˆ¥å®šç¾©æª”æ¡ˆä¸å­˜åœ¨")
                
            with open(COCO_ANNOTATIONS_PATH, "r", encoding='utf-8') as f:
                coco_data = json.load(f)
            
            categories = sorted(coco_data['categories'], key=lambda x: x['id'])
            self.class_names = [cat['name'] for cat in categories]
            
            logger.info(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.class_names)} å€‹é¡åˆ¥")
            logger.info(f"ğŸ“‹ é¡åˆ¥: {self.class_names}")
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥é¡åˆ¥åç¨±å¤±æ•—: {str(e)}")
            raise Exception("é¡åˆ¥å®šç¾©è¼‰å…¥å¤±æ•—")
            
    def preprocess_image(self, image_array: np.ndarray) -> Tuple[np.ndarray, Image.Image]:
        """
        é è™•ç†å¯¦ç¾ - åƒè€ƒRF-DETRå®˜æ–¹æµç¨‹
        
        æ“ä½œé †åºï¼šresize â†’ to_tensor â†’ normalize
        
        é †åºèª¿æ•´åŸå› ï¼š
        - RF-DETRå®˜æ–¹: PIL â†’ to_tensor â†’ normalize â†’ resize
        - ä¿®æ”¹å¾Œæ–¹æ¡ˆ: PIL â†’ resize â†’ to_tensor â†’ normalize
        - åœ¨åŸå§‹åƒç´ åŸŸï¼ˆuint8 [0,255]ï¼‰resizeé¿å…æ¨™æº–åŒ–æ•¸æ“šçš„ç²¾åº¦æå¤±
        
        å…·é«”æµç¨‹ï¼š
        1. numpy array â†’ PIL Image
        2. é•·å¯¬æ¯”ä¿æŒresize + é»‘è‰²paddingåˆ°560x560
        3. PIL â†’ tensor (CHW format, [0,1] range)
        4. ImageNetæ¨™æº–åŒ–: (pixel - mean) / std
        5. æ·»åŠ batchç¶­åº¦: (1, C, H, W)
        
        Args:
            image_array: è¼¸å…¥åœ–åƒnumpyé™£åˆ— (H,W,C) uint8 [0,255]
            
        Returns:
            (input_tensor, processed_image): 
            - input_tensor: ONNXæ¨¡å‹è¼¸å…¥ (1,C,H,W) float32ï¼ŒImageNetæ¨™æº–åŒ–
            - processed_image: è™•ç†å¾Œçš„PILåœ–åƒ (560,560) RGBï¼Œç”¨æ–¼å¾ŒçºŒåº§æ¨™è¨ˆç®—
            
        åƒè€ƒï¼šlegacy/elegant_solution_spec.md
        """
        try:
            # === æ­¥é©Ÿ1: å°‡ numpy array è½‰ç‚º PIL Image ===
            pil_image = Image.fromarray(image_array.astype(np.uint8))
            
            # === æ­¥é©Ÿ2: ä¿æŒé•·å¯¬æ¯”resize + paddingåˆ°560x560 ===
            target_h, target_w = INPUT_SIZE[1], INPUT_SIZE[0]  # INPUT_SIZE æ˜¯ (width, height)
            
            # è¨ˆç®—ä¿æŒé•·å¯¬æ¯”çš„ç¸®æ”¾æ¯”ä¾‹
            original_w, original_h = pil_image.size
            scale = min(target_w / original_w, target_h / original_h)
            new_w = int(original_w * scale)
            new_h = int(original_h * scale)
            
            # å…ˆresizeåˆ°åˆé©å¤§å°ï¼ˆä¿æŒé•·å¯¬æ¯”ï¼‰
            resized_pil = pil_image.resize((new_w, new_h), Image.Resampling.BILINEAR)
            
            # å‰µå»º560x560çš„é»‘è‰²èƒŒæ™¯åœ–ç‰‡
            padded_pil = Image.new('RGB', (target_w, target_h), (0, 0, 0))
            
            # è¨ˆç®—å±…ä¸­ä½ç½®
            paste_x = (target_w - new_w) // 2
            paste_y = (target_h - new_h) // 2
            
            # å°‡resizeå¾Œçš„åœ–ç‰‡è²¼åˆ°ä¸­å¿ƒ
            padded_pil.paste(resized_pil, (paste_x, paste_y))
            resized_pil = padded_pil
            
            # === æ­¥é©Ÿ3: to_tensor ===
            # PIL Image (H,W,C) uint8 [0,255] â†’ numpy (C,H,W) float32 [0,1]
            np_img = np.array(resized_pil).astype(np.float32) / 255.0  # [0,1]
            tensor_img = np.transpose(np_img, (2, 0, 1))  # HWC â†’ CHW
            
            # === æ­¥é©Ÿ4: normalize ===
            # ImageNet æ¨™æº–åŒ–: normalized = (image - mean) / std
            means = np.array(IMAGENET_MEAN, dtype=np.float32).reshape(3, 1, 1)
            stds = np.array(IMAGENET_STD, dtype=np.float32).reshape(3, 1, 1)
            normalized_img = (tensor_img - means) / stds
            
            # === æ­¥é©Ÿ5: æ·»åŠ  batch ç¶­åº¦ ===
            # (C, H, W) â†’ (1, C, H, W)
            batched = np.expand_dims(normalized_img, axis=0)
            
            return batched, resized_pil
            
        except Exception as e:
            logger.error(f"âŒ åœ–åƒé è™•ç†å¤±æ•—: {e}")
            raise
        
    def postprocess_results(self, outputs) -> List[Dict]:
        """
        ONNXæ¨¡å‹è¼¸å‡ºå¾Œè™•ç†
        
        Args:
            outputs: ONNX Runtimeæ¨¡å‹è¼¸å‡ºåˆ—è¡¨ [pred_boxes, pred_logits]
            
        Returns:
            List[Dict]: æª¢æ¸¬çµæœåˆ—è¡¨ï¼ŒåŒ…å« class_id, class_name, confidence, bbox
        """
        try:
            # === æ­¥é©Ÿ1: æå–æ¨¡å‹è¼¸å‡º ===
            # æ¨¡å‹è¼¸å‡ºæ ¼å¼ï¼š[boxes, logits]
            pred_boxes = outputs[0]   # (1, 300, 4) é‚Šç•Œæ¡†é æ¸¬
            pred_logits = outputs[1]  # (1, 300, num_classes) é¡åˆ¥é æ¸¬
            
            # ä½¿ç”¨ä¿®æ”¹æ–¹æ¡ˆçš„å¾Œè™•ç†å‡½æ•¸ï¼ˆåœ–åƒå°ºå¯¸å›ºå®šç‚º560Ã—560ï¼‰
            detections = self._postprocess_detections(
                pred_logits, pred_boxes, 
                threshold=CONFIDENCE_THRESHOLD, 
                top_k=TOP_K
            )
            
            # åˆ†æç›¸ä¼¼å¤–è§€æª¢æ¸¬
            similar_pairs = []
            if 'pre_nms_candidates' in detections:
                similar_pairs = self._find_similar_appearance_detections(detections['pre_nms_candidates'])
            
            # è½‰æ›ç‚º API è¼¸å‡ºæ ¼å¼
            results = []
            for i in range(len(detections['xyxy'])):
                x1, y1, x2, y2 = detections['xyxy'][i]
                class_id = int(detections['class_id'][i])
                confidence = float(detections['confidence'][i])
                
                # ç²å–è‹±æ–‡è—¥å
                english_name = self.class_names[class_id] if self.class_names and class_id < len(self.class_names) else f'Class_{class_id}'
                
                # è½‰æ›ç‚ºä¸­æ–‡è—¥å
                chinese_name = CHINESE_DRUG_NAMES.get(english_name, english_name)
                
                results.append({
                    'class_id': class_id,
                    'class_name': chinese_name,
                    'class_name_en': english_name,
                    'class_name_zh': chinese_name,
                    'confidence': confidence,
                    'bbox': [int(x1), int(y1), int(x2), int(y2)]
                })
            
            # è¿”å›çµæœæ™‚åŒ…å«ç›¸ä¼¼å¤–è§€æª¢æ¸¬ä¿¡æ¯
            return {
                'detections': results,
                'similar_appearance_pairs': similar_pairs
            }
                
        except Exception as e:
            logger.error(f"âŒ å¾Œè™•ç†å¤±æ•—: {e}")
            return []
            
    def _postprocess_detections(self, logits, boxes, threshold=0.7, top_k=30):
        """
        å¾Œè™•ç†æ ¸å¿ƒå¯¦ç¾ - æ¯ä½ç½®æœ€é«˜åˆ†é¡ + NMS ç­–ç•¥
        
        æµç¨‹: sigmoidæ¿€æ´» â†’ æ¯ä½ç½®æœ€é«˜åˆ†é¡ â†’ é–¾å€¼éæ¿¾ â†’ NMS â†’ Top-Ké¸æ“‡ â†’ åº§æ¨™è½‰æ›
        
        Args:
            logits: (1, 300, num_classes) é¡åˆ¥é æ¸¬
            boxes: (1, 300, 4) æ¡†é æ¸¬ï¼Œcxcywhæ ¼å¼
            threshold: ä¿¡å¿ƒåº¦é–¾å€¼
            top_k: æœ€å¤§æª¢æ¸¬æ•¸é‡
            
        Returns:
            Dict: åŒ…å« 'xyxy', 'confidence', 'class_id' çš„æª¢æ¸¬çµæœ
        """
        # ç§»é™¤æ‰¹æ¬¡ç¶­åº¦
        logits = logits[0]  # (300, num_classes)
        boxes = boxes[0]    # (300, 4)
        
        # è¨ˆç®—ä¿¡å¿ƒåº¦ï¼ˆä½¿ç”¨ sigmoidï¼‰
        scores = 1 / (1 + np.exp(-logits))  # sigmoid å‡½æ•¸
        
        # æ­¥é©Ÿ1ï¼šæ¯å€‹ä½ç½®å–æœ€é«˜åˆ†é¡
        max_scores = np.max(scores, axis=1)  # (300,) æ¯å€‹ä½ç½®çš„æœ€é«˜åˆ†æ•¸
        max_classes = np.argmax(scores, axis=1)  # (300,) æ¯å€‹ä½ç½®çš„æœ€ä½³é¡åˆ¥
        
        # æ­¥é©Ÿ2ï¼šé–¾å€¼éæ¿¾
        keep_mask = max_scores > threshold
        if not np.any(keep_mask):
            return {'xyxy': np.array([]).reshape(0, 4), 'confidence': np.array([]), 'class_id': np.array([])}
            
        filtered_scores = max_scores[keep_mask]
        filtered_classes = max_classes[keep_mask]
        filtered_boxes = boxes[keep_mask]
        
        # æ­¥é©Ÿ3ï¼šåº§æ¨™è½‰æ› (åœ¨NMSä¹‹å‰é€²è¡Œï¼Œå› ç‚ºNMSéœ€è¦xyxyæ ¼å¼)
        xyxy_boxes = CoordinateUtils.cxcywh_to_xyxy(filtered_boxes)
        target_size = INPUT_SIZE[0]  # ä½¿ç”¨é…ç½®ä¸­çš„å°ºå¯¸ï¼ˆwidth = heightï¼‰
        scaled_boxes = xyxy_boxes * target_size
        
        # æ­¥é©Ÿ4ï¼šä¿å­˜ NMS å‰çš„å€™é¸æª¢æ¸¬ï¼ˆç”¨æ–¼ç›¸ä¼¼å¤–è§€åˆ†æï¼‰
        pre_nms_candidates = {
            'boxes': scaled_boxes.copy(),
            'scores': filtered_scores.copy(), 
            'classes': filtered_classes.copy()
        }
        
        # æ­¥é©Ÿ5ï¼šNMS (éæ¥µå¤§å€¼æŠ‘åˆ¶) - ç§»é™¤é‡è¤‡æª¢æ¸¬
        from .config import NMS_IOU_THRESHOLD
        nms_boxes, nms_scores, nms_classes = CoordinateUtils.non_max_suppression(
            scaled_boxes, filtered_scores, filtered_classes, 
            iou_threshold=NMS_IOU_THRESHOLD
        )
        
        # æ­¥é©Ÿ6ï¼šTop-K é¸æ“‡ï¼ˆåœ¨NMSå¾Œçš„çµæœä¸­é¸æ“‡ï¼‰
        if len(nms_scores) > top_k:
            top_indices = np.argsort(nms_scores)[-top_k:]
            final_boxes = nms_boxes[top_indices]
            final_scores = nms_scores[top_indices]
            final_classes = nms_classes[top_indices]
        else:
            final_boxes = nms_boxes
            final_scores = nms_scores
            final_classes = nms_classes
        
        return {
            'xyxy': final_boxes,
            'confidence': final_scores,
            'class_id': final_classes,
            'pre_nms_candidates': pre_nms_candidates  # æ–°å¢ï¼šNMS å‰çš„å€™é¸æª¢æ¸¬
        }
    
    def _find_similar_appearance_detections(self, pre_nms_candidates: Dict) -> List[Tuple[int, int]]:
        """
        æª¢æ¸¬ç›¸ä¼¼å¤–è§€æƒ…æ³ï¼šåŒä½ç½®æœ‰å¤šå€‹ä¸åŒé¡åˆ¥ä¸”ä¿¡å¿ƒåº¦ç›¸è¿‘çš„æª¢æ¸¬
        
        Args:
            pre_nms_candidates: NMS å‰çš„å€™é¸æª¢æ¸¬ï¼ŒåŒ…å« 'boxes', 'scores', 'classes'
            
        Returns:
            List[Tuple[int, int]]: ç›¸ä¼¼å¤–è§€æª¢æ¸¬å°çš„ç´¢å¼•åˆ—è¡¨
        """
        from .config import SIMILAR_POSITION_IOU_THRESHOLD, SIMILAR_CONFIDENCE_THRESHOLD
        from .utils.coordinate_utils import CoordinateUtils
        
        boxes = pre_nms_candidates['boxes']
        scores = pre_nms_candidates['scores'] 
        classes = pre_nms_candidates['classes']
        
        similar_pairs = []
        
        # é€å°æ¯”è¼ƒæ‰€æœ‰å€™é¸æª¢æ¸¬
        for i in range(len(boxes)):
            for j in range(i + 1, len(boxes)):
                # æª¢æŸ¥æ˜¯å¦ç‚ºä¸åŒé¡åˆ¥
                if classes[i] != classes[j]:
                    # è¨ˆç®—ä½ç½®ç›¸ä¼¼æ€§ (IoU)
                    iou = CoordinateUtils.calculate_iou(boxes[i], boxes[j])
                    
                    if iou > SIMILAR_POSITION_IOU_THRESHOLD:
                        # æª¢æŸ¥ä¿¡å¿ƒåº¦ç›¸ä¼¼æ€§
                        confidence_diff = abs(scores[i] - scores[j])
                        
                        if confidence_diff < SIMILAR_CONFIDENCE_THRESHOLD:
                            similar_pairs.append((i, j))
        
        return similar_pairs
        
    def get_classes(self) -> List[Dict[str, str]]:
        """
        å–å¾—æ‰€æœ‰æ”¯æ´çš„è—¥ä¸¸é¡åˆ¥åç¨±ï¼ˆåŒ…å«ä¸­è‹±æ–‡ï¼‰
        
        å¾COCOæ¨™è¨»æ–‡ä»¶è¼‰å…¥çš„é¡åˆ¥æ¸…å–®ï¼Œç”¨æ–¼APIç«¯é» /classes
        
        Returns:
            List[Dict[str, str]]: è—¥ä¸¸é¡åˆ¥åç¨±åˆ—è¡¨ï¼Œä¾ç…§COCOé¡åˆ¥IDæ’åº
                                 æ¯å€‹é …ç›®åŒ…å«è‹±æ–‡åç¨±å’Œä¸­æ–‡åç¨±
                                 ä¾‹å¦‚: [{'english': 'Amoxicillin', 'chinese': 'å®‰è«è¥¿æ—è† å›Š'}, ...]
        """
        if not self.class_names:
            return []
        
        result = []
        for class_name in self.class_names:
            # è·³éèƒŒæ™¯é¡åˆ¥
            if class_name == "objects-P70T-danO":
                continue
            
            result.append({
                "english": class_name,
                "chinese": CHINESE_DRUG_NAMES.get(class_name, class_name)
            })
        
        return result
        
    def is_ready(self) -> bool:
        """
        æª¢æŸ¥æª¢æ¸¬å™¨æ˜¯å¦å·²å®Œæˆåˆå§‹åŒ–
        
        é©—è­‰ONNXæ¨¡å‹å’Œé¡åˆ¥åç¨±æ˜¯å¦éƒ½å·²æˆåŠŸè¼‰å…¥ï¼Œ
        ç¢ºä¿æª¢æ¸¬å™¨å¯ä»¥æ­£å¸¸åŸ·è¡Œæ¨ç†ä»»å‹™ã€‚
        
        Returns:
            bool: Trueè¡¨ç¤ºæª¢æ¸¬å™¨å·²å°±ç·’ï¼ŒFalseè¡¨ç¤ºä»åœ¨åˆå§‹åŒ–ä¸­
        """
        return self.onnx_session is not None and self.class_names is not None
    
